{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. (Optional) Extract video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1547\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "capture = cv2.VideoCapture(\"conering.avi\")\n",
    "assert capture.isOpened(), \"Cannot open the video file.\"\n",
    "\n",
    "num_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(num_frames)\n",
    "# sample_interval = num_frames//180\n",
    "# Prepare folders\n",
    "img_filename_fmt = 'dataset/images_corner/frame_{:09d}.jpg'\n",
    "dirname = os.path.dirname(img_filename_fmt)\n",
    "os.makedirs(dirname, exist_ok=True)\n",
    "for ii in range(num_frames):\n",
    "    capture.set(cv2.CAP_PROP_POS_FRAMES, ii)\n",
    "    _, frame = capture.read()\n",
    "    cv2.imwrite(img_filename_fmt.format(ii), frame)\n",
    "\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File renaming completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 원본 이미지가 저장된 디렉토리\n",
    "source_dir = 'dataset/images_corner'\n",
    "\n",
    "# 파일 목록 가져오기\n",
    "files = os.listdir(source_dir)\n",
    "files = sorted(files)  # 파일 이름 순으로 정렬\n",
    "\n",
    "# 파일 이름 변경\n",
    "for index, filename in enumerate(files):\n",
    "    # 새 파일 이름 형식\n",
    "    new_filename = f\"frame_{index:09d}.jpg\"\n",
    "    # 원본 파일의 전체 경로\n",
    "    old_path = os.path.join(source_dir, filename)\n",
    "    # 새 파일의 전체 경로\n",
    "    new_path = os.path.join(source_dir, new_filename)\n",
    "    # 파일 이름 변경\n",
    "    os.rename(old_path, new_path)\n",
    "\n",
    "print(\"File renaming completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample images and remaining images have been processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np  # numpy 라이브러리 추가\n",
    "\n",
    "# 이미지 파일 경로 설정\n",
    "source_dir = 'dataset/images_corner'  # 원본 이미지가 저장된 폴더\n",
    "sample_dir = 'dataset/sample_corner_A'  # 샘플 이미지를 저장할 폴더\n",
    "move_dir = 'dataset/sample_corner_B'  # 나머지 이미지를 이동할 폴더\n",
    "\n",
    "# 샘플과 나머지 이미지 저장 폴더 생성\n",
    "os.makedirs(sample_dir, exist_ok=True)\n",
    "os.makedirs(move_dir, exist_ok=True)\n",
    "\n",
    "# 이미지 파일 목록 생성 및 정렬\n",
    "image_files = ['frame_{:09d}.jpg'.format(i) for i in range(1461)]  # 289부터 3253까지\n",
    "image_files = sorted(image_files)  # 파일 정렬\n",
    "\n",
    "# 샘플링할 이미지 수\n",
    "num_samples = 200\n",
    "\n",
    "# 샘플링 인덱스 계산\n",
    "indices = [int(i) for i in np.linspace(0, len(image_files) - 1, num_samples)]\n",
    "\n",
    "# 샘플 이미지 저장 및 나머지 이미지 이동\n",
    "for idx, filename in enumerate(image_files):\n",
    "    src_path = os.path.join(source_dir, filename)\n",
    "    if idx in indices:\n",
    "        # 샘플 이미지는 샘플 폴더에 복사\n",
    "        shutil.copy(src_path, os.path.join(sample_dir, filename))\n",
    "    else:\n",
    "        # 나머지 이미지는 이동 폴더로 이동\n",
    "        shutil.move(src_path, os.path.join(move_dir, filename))\n",
    "\n",
    "print(\"Sample images and remaining images have been processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Label images\n",
    "\n",
    "- Assume all images have same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'handle_next_button' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m yslider\u001b[38;5;241m.\u001b[39mobserve(handle_slider_change, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    100\u001b[0m prev_btn\u001b[38;5;241m.\u001b[39mon_click(handle_prev_button)\n\u001b[0;32m--> 101\u001b[0m next_btn\u001b[38;5;241m.\u001b[39mon_click(\u001b[43mhandle_next_button\u001b[49m)\n\u001b[1;32m    102\u001b[0m save_btn\u001b[38;5;241m.\u001b[39mon_click(handle_save_button)\n\u001b[1;32m    104\u001b[0m display(canvas, HBox([cur_fname, cur_pos, yslider]), HBox([prev_btn, next_btn, save_btn]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'handle_next_button' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict\n",
    "from ipywidgets import IntSlider, Label, Button, HBox\n",
    "from ipycanvas import MultiCanvas, hold_canvas\n",
    "\n",
    "thickness = 3\n",
    "y_ratio = 0.7     # percentile of y-position from the top\n",
    "    \n",
    "# Input images\n",
    "img_filename_fmt = 'dataset/images_new_straight/frame_{:09d}.jpg'\n",
    "ann_filename = 'dataset/annotation_new_straight.txt'\n",
    "ann_dict = OrderedDict()\n",
    "\n",
    "num_frames = len(os.listdir(os.path.dirname(img_filename_fmt)))\n",
    "\n",
    "cur_index = 0\n",
    "height, width = cv2.imread(img_filename_fmt.format(cur_index)).shape[:2]\n",
    "y_value = int(height * y_ratio)\n",
    "\n",
    "def set_image():        \n",
    "    image = cv2.imread(img_filename_fmt.format(cur_index))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)    \n",
    "    image[y_value-thickness//2:y_value+thickness//2] = (255, 0, 0)\n",
    "\n",
    "    canvas[0].clear()\n",
    "    canvas[0].put_image_data(image, 0, 0)\n",
    "    canvas[0].flush()\n",
    "\n",
    "    pos = ann_dict.get(img_filename_fmt.format(cur_index))\n",
    "    if pos is not None:\n",
    "        handle_mouse_down(pos[0], pos[1])    \n",
    "\n",
    "    cur_fname.value = 'Current image: {:s} | '.format(img_filename_fmt.format(cur_index))\n",
    "\n",
    "def handle_mouse_move(xpos, ypos):\n",
    "    with hold_canvas():\n",
    "        canvas[1].clear()  # Clear the old animation step\n",
    "        canvas[1].fill_style = \"yellow\"\n",
    "        canvas[1].fill_circle(xpos, y_value, 5)  # Draw the new frame    \n",
    "\n",
    "def handle_mouse_down(xpos, ypos):    \n",
    "    with hold_canvas():\n",
    "        canvas[2].clear()\n",
    "        canvas[2].fill_style = \"green\"\n",
    "        canvas[2].fill_circle(xpos, y_value, 5)  # Draw the new frame    \n",
    "\n",
    "    cur_pos.value = \"({:d}, {:d}) \".format(xpos, y_value)    \n",
    "    ann_dict[img_filename_fmt.format(cur_index)] = (xpos, y_value)\n",
    "    \n",
    "def handle_slider_change(change):\n",
    "    global y_value\n",
    "    y_value = change.new\n",
    "    set_image()\n",
    "    canvas[1].clear()\n",
    "    canvas[2].clear()\n",
    "\n",
    "def handle_save_button(b):\n",
    "    with open(ann_filename, 'w') as f:\n",
    "        for k, v in ann_dict.items():            \n",
    "            f.write(\"{:s}\\t{:d}\\t{:d}\\n\".format(k, v[0], v[1]))    \n",
    "\n",
    "def handle_prev_button(b):\n",
    "    global cur_index\n",
    "    cur_index = max(0, cur_index - 1)\n",
    "    canvas.clear()\n",
    "    set_image()\n",
    "\n",
    "def handle_next_button(key, shift_key, ctrl_key, meta_key):\n",
    "    global cur_index\n",
    "    cur_index = min(num_frames - 1, cur_index + 1)\n",
    "    canvas.clear()\n",
    "    set_image()\n",
    "\n",
    "    \n",
    "canvas = MultiCanvas(3, width=width, height=height)\n",
    "cur_fname = Label(value='', disabled=False)\n",
    "cur_pos = Label(value='', disabled=True)\n",
    "yslider = IntSlider(description=\"Y-bar: \", stype={'description_width': 'initial'}, value=y_value, min=1, max=height-2, step=1)\n",
    "prev_btn = Button(description='Prev', icon='arrow-left')\n",
    "next_btn = Button(description='Next', icon='arrow-right')\n",
    "save_btn = Button(description='Save labels', icon='check')\n",
    "\n",
    "set_image()\n",
    "canvas.on_mouse_move(handle_mouse_move)\n",
    "canvas.on_mouse_down(handle_mouse_down)\n",
    "yslider.observe(handle_slider_change, names='value')\n",
    "\n",
    "prev_btn.on_click(handle_prev_button)\n",
    "next_btn.on_click(handle_next_button)\n",
    "save_btn.on_click(handle_save_button)\n",
    "\n",
    "display(canvas, HBox([cur_fname, cur_pos, yslider]), HBox([prev_btn, next_btn, save_btn]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "def get_model():\n",
    "    model = torchvision.models.alexnet(num_classes=2, dropout=0.0)\n",
    "    return model\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = get_model()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cnn.center_dataset import CenterDataset\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "dataset = CenterDataset('dataset', random_hflip=False)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=0,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import torch.nn.functional as f\n",
    "\n",
    "epoch = 200\n",
    "learning_rate = 2e-3\n",
    "# learning_rate = 2e-4\n",
    "\n",
    "epoch_slider = ipywidgets.IntSlider(description='Epochs', value=epoch, min=1, max=200, step=1)\n",
    "lr_slider = ipywidgets.FloatSlider(description='lr', value=learning_rate, min=1e-4, max=1e-2, step=1e-4, readout_format='.4f')\n",
    "train_button = ipywidgets.Button(description='Train', icon='tasks')\n",
    "loss_text = ipywidgets.Textarea(description='Progress', value='', rows=15, layout=ipywidgets.Layout(width=\"50%\", height=\"auto\"))\n",
    "layout = ipywidgets.VBox([ipywidgets.HBox([epoch_slider, lr_slider, train_button]), loss_text])\n",
    "\n",
    "\n",
    "def train_model(b):\n",
    "    global epoch_slider\n",
    "    for epoch in range(epoch_slider.value):\n",
    "        loss_text.value += \"<<<<< Epoch {:d} >>>>>\\n\".format(epoch)\n",
    "        train_step()                \n",
    "\n",
    "\n",
    "def train_step():\n",
    "    global model, lr_slider, loss_text, train_laoder, device\n",
    "\n",
    "    try:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        # optimizer = torch.optim.SGD(model.parameters(), lr=lr_slider.value, momentum=0.9)\n",
    "\n",
    "        train_button.disabled = True                \n",
    "        model = model.train()        \n",
    "\n",
    "        num_iters = len(train_loader)\n",
    "        for ii, (images, labels) in enumerate(train_loader):\n",
    "            # send data to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # zero gradients of parameters\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # execute model to get outputs\n",
    "            outputs = model(images)\n",
    "\n",
    "            # compute MSE loss over x coordinates            \n",
    "            loss = f.mse_loss(outputs, labels, reduction='sum')\n",
    "\n",
    "            # run backpropogation to accumulate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step optimizer to adjust parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            if ii % 10 == 0:\n",
    "                xlbl, ylbl = labels[0].cpu()\n",
    "                xlbl = ( xlbl.item() / 2 + 0.5 ) * 800\n",
    "                ylbl = ( ylbl.item() / 2 + 0.5 ) * 450\n",
    "\n",
    "                xpre, ypre = outputs[0].cpu()\n",
    "                xpre = ( xpre.item() / 2 + 0.5 ) * 800\n",
    "                ypre = ( ypre.item() / 2 + 0.5 ) * 450\n",
    "\n",
    "                msg = \"[{:04d} / {:04d}] loss: {:.4f} | labels: ({:.2f}, {:.2f}), outpus: ({:.2f}, {:.2f})\\n\".format(ii, num_iters, loss.item(), xlbl, ylbl, xpre, ypre)\n",
    "                loss_text.value += msg                \n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "        \n",
    "    model = model.eval()\n",
    "    torch.save(model.state_dict(), 'road_following_model.pth')\n",
    "    \n",
    "    train_button.disabled = False\n",
    "    \n",
    "train_button.on_click(train_model)    \n",
    "\n",
    "display(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "from cnn.center_dataset import TEST_TRANSFORMS\n",
    "\n",
    "def preprocess(image: PIL.Image):\n",
    "    device = torch.device('cuda')    \n",
    "    image = TEST_TRANSFORMS(image).to(device)\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.load_state_dict(torch.load('road_following_model.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "# from torch2trt import TRTModule\n",
    "# model = TRTModule()\n",
    "# model.load_state_dict(torch.load('road_following_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "img_filename_fmt = 'dataset/images/frame_{:09d}.jpg'\n",
    "ann_filename = 'dataset/annotation.txt'\n",
    "with open(ann_filename, 'r') as f:\n",
    "    data = [line.split() for line in f.readlines()]\n",
    "\n",
    "filename, xpos, ypos = data[3]\n",
    "\n",
    "xpos = int(xpos)\n",
    "ypos = int(ypos)\n",
    "\n",
    "image_ori = PIL.Image.open(filename)\n",
    "width = image_ori.width\n",
    "height = image_ori.height\n",
    "\n",
    "with torch.no_grad():\n",
    "    image = preprocess(image_ori)\n",
    "    output = model(image).detach().cpu().numpy()\n",
    "x, y = output[0]\n",
    "\n",
    "x = (x / 2 + 0.5) * width\n",
    "y = (y / 2 + 0.5) * height\n",
    "print(x, y)\n",
    "\n",
    "image_np = copy.deepcopy(np.asarray(image_ori))\n",
    "cv2.circle(image_np, (int(x), int(y)), radius=5, color=(255, 0, 0))  # Pred\n",
    "cv2.circle(image_np, (xpos, ypos), radius=5, color=(0, 255, 0))     # GT\n",
    "\n",
    "PIL.Image.fromarray(image_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
